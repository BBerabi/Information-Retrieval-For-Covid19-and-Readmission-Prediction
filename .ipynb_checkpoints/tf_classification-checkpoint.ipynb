{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data_original = data.copy()\n",
    "    data = data.replace('?', np.NaN)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    # weights, payer_code, diag_1_desc, diag_2_desc, diag_3_desc\n",
    "    data.drop(labels=['weight', 'payer_code', 'diag_1_desc', 'diag_2_desc', 'diag_3_desc'], axis=1, inplace=True)\n",
    "\n",
    "    data['diag_1'] = group_diagnoses(data['diag_1'])\n",
    "    data['diag_2'] = group_diagnoses(data['diag_2'])\n",
    "    data['diag_3'] = group_diagnoses(data['diag_3'])\n",
    "\n",
    "    # Encode string data to numericals\n",
    "    to_cat = list(data.select_dtypes(['object']).columns)\n",
    "    data[to_cat] = data[to_cat].astype('category')\n",
    "    cat_columns = data.select_dtypes(['category']).columns\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "    # Get Readmitted as labels\n",
    "    labels = data['readmitted']\n",
    "    data.drop(labels=['readmitted'], axis=1, inplace=True)\n",
    "    # data = data.replace(-1, np.NaN)\n",
    "   \n",
    "    #names = ['diag_1_desc', 'diag_2_desc', 'diag_3_desc']\n",
    "#     for col in names:\n",
    "#         features = extract_textual_features(data_original, col)\n",
    "#         data = pd.concat([data, features], axis=1)\n",
    "\n",
    "    return labels.values.ravel(), data.values\n",
    "\n",
    "\n",
    "def extract_textual_features(data, colname):\n",
    "    corpus = data[colname]\n",
    "    corpus = corpus.replace(np.NaN, '').values\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=0.0001)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    text_features = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "    return text_features\n",
    "\n",
    "\n",
    "def group_diagnoses(df):\n",
    "    # Create mapping from\n",
    "    l_old = []\n",
    "    l_new = []\n",
    "\n",
    "    idx = 0\n",
    "    tmp_list1 = list(range(390, 460))\n",
    "    tmp_list1 += [785]\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = list(range(460, 520))\n",
    "    tmp_list1 += [786]\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = list(range(520, 579))\n",
    "    tmp_list1 += [787]\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = [str(i) for i in list(np.arange(250, 251, 0.01))]\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = range(800, 1000)\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = range(710, 740)\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = list(range(580, 630))\n",
    "    tmp_list1 += [788]\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    tmp_list1 = range(140, 240)\n",
    "    tmp_list2 = [idx] * len(tmp_list1)\n",
    "    idx += 1\n",
    "    l_old = [*l_old, *tmp_list1]\n",
    "    l_new = [*l_new, *tmp_list2]\n",
    "\n",
    "    l_old = [str(i) for i in l_old]\n",
    "    d = dict(zip(l_old, l_new))\n",
    "\n",
    "    df_new = df.copy()\n",
    "\n",
    "    df_new = df_new.map(d)\n",
    "    df_new = df_new.replace(df_new[pd.isna(df_new)], 8)\n",
    "    df_new = df_new.astype(int)\n",
    "    return df_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('task1/data/diab_train.csv', index_col=0)\n",
    "data_test = pd.read_csv('task1/data/diab_test.csv', index_col=0)\n",
    "data_validation = pd.read_csv('task1/data/diab_validation.csv', index_col=0)\n",
    "\n",
    "data_train = pd.concat([data_train, data_validation, data_test], axis=0)\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "data = data_train.copy()\n",
    "y, X = preprocess_data(data_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>...</th>\n",
       "      <th>glipizide.metformin</th>\n",
       "      <th>glimepiride.pioglitazone</th>\n",
       "      <th>metformin.rosiglitazone</th>\n",
       "      <th>metformin.pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>diag_1_desc</th>\n",
       "      <th>diag_2_desc</th>\n",
       "      <th>diag_3_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>?</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>4</td>\n",
       "      <td>MC</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Acute pericarditis in diseases classified else...</td>\n",
       "      <td>Secondary malignant neoplasm of kidney</td>\n",
       "      <td>Congestive heart failure, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>Elective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Physician Referral</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Family/GeneralPractice</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Malignant essential hypertension</td>\n",
       "      <td>Spinal stenosis, unspecified region</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Discharged/transferred to SNF</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>2</td>\n",
       "      <td>MC</td>\n",
       "      <td>Emergency/Trauma</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Urinary tract infection, site not specified</td>\n",
       "      <td>Streptococcus infection in conditions classifi...</td>\n",
       "      <td>Congestive heart failure, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>?</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Respiratory abnormality, unspecified</td>\n",
       "      <td>Hypertensive chronic kidney disease, malignant...</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>Elective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Physician Referral</td>\n",
       "      <td>13</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Coronary atherosclerosis of unspecified type o...</td>\n",
       "      <td>Chronic airway obstruction, not elsewhere clas...</td>\n",
       "      <td>Malignant essential hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>?</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Transfer from a hospital</td>\n",
       "      <td>1</td>\n",
       "      <td>UN</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Coronary atherosclerosis of unspecified type o...</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "      <td>Pure hypercholesterolemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Discharged/transferred to SNF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Atherosclerosis of aorta</td>\n",
       "      <td>Endomyocardial fibrosis</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>Elective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Physician Referral</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>Urology</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant neoplasm of prostate</td>\n",
       "      <td>Hypertrophy (benign) of prostate without urina...</td>\n",
       "      <td>Obesity, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>?</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>InternalMedicine</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Cellulitis and abscess of face</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>Elective</td>\n",
       "      <td>Discharged/transferred to another rehab fac in...</td>\n",
       "      <td>Physician Referral</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Occlusion and stenosis of basilar artery witho...</td>\n",
       "      <td>Malignant essential hypertension</td>\n",
       "      <td>Diabetes mellitus without mention of complicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 race  gender      age weight admission_type_id  \\\n",
       "0     AfricanAmerican    Male  [60-70)      ?         Emergency   \n",
       "1           Caucasian  Female  [70-80)      ?          Elective   \n",
       "2           Caucasian  Female  [80-90)      ?            Urgent   \n",
       "3     AfricanAmerican  Female  [50-60)      ?         Emergency   \n",
       "4           Caucasian    Male  [80-90)      ?          Elective   \n",
       "...               ...     ...      ...    ...               ...   \n",
       "9995                ?    Male  [40-50)      ?            Urgent   \n",
       "9996        Caucasian    Male  [80-90)      ?     Not Available   \n",
       "9997  AfricanAmerican    Male  [40-50)      ?          Elective   \n",
       "9998  AfricanAmerican    Male  [50-60)      ?         Emergency   \n",
       "9999        Caucasian  Female  [80-90)      ?          Elective   \n",
       "\n",
       "                               discharge_disposition_id  \\\n",
       "0                                    Discharged to home   \n",
       "1                                                   NaN   \n",
       "2                         Discharged/transferred to SNF   \n",
       "3                                    Discharged to home   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "9995                                 Discharged to home   \n",
       "9996                      Discharged/transferred to SNF   \n",
       "9997                                                NaN   \n",
       "9998                                 Discharged to home   \n",
       "9999  Discharged/transferred to another rehab fac in...   \n",
       "\n",
       "           admission_source_id  time_in_hospital payer_code  \\\n",
       "0               Emergency Room                 4         MC   \n",
       "1           Physician Referral                 1          ?   \n",
       "2               Emergency Room                 2         MC   \n",
       "3               Emergency Room                 4         DM   \n",
       "4           Physician Referral                13          ?   \n",
       "...                        ...               ...        ...   \n",
       "9995  Transfer from a hospital                 1         UN   \n",
       "9996                       NaN                 6          ?   \n",
       "9997        Physician Referral                 4          ?   \n",
       "9998            Emergency Room                 2          ?   \n",
       "9999        Physician Referral                 1         CM   \n",
       "\n",
       "           medical_specialty  ...  glipizide.metformin  \\\n",
       "0                          ?  ...                   No   \n",
       "1     Family/GeneralPractice  ...                   No   \n",
       "2           Emergency/Trauma  ...                   No   \n",
       "3                          ?  ...                   No   \n",
       "4                          ?  ...                   No   \n",
       "...                      ...  ...                  ...   \n",
       "9995              Cardiology  ...                   No   \n",
       "9996                       ?  ...                   No   \n",
       "9997                 Urology  ...                   No   \n",
       "9998        InternalMedicine  ...                   No   \n",
       "9999                       ?  ...                   No   \n",
       "\n",
       "      glimepiride.pioglitazone  metformin.rosiglitazone  \\\n",
       "0                           No                       No   \n",
       "1                           No                       No   \n",
       "2                           No                       No   \n",
       "3                           No                       No   \n",
       "4                           No                       No   \n",
       "...                        ...                      ...   \n",
       "9995                        No                       No   \n",
       "9996                        No                       No   \n",
       "9997                        No                       No   \n",
       "9998                        No                       No   \n",
       "9999                        No                       No   \n",
       "\n",
       "      metformin.pioglitazone  change  diabetesMed readmitted  \\\n",
       "0                         No      No           No          0   \n",
       "1                         No      Ch          Yes          1   \n",
       "2                         No      Ch          Yes          0   \n",
       "3                         No      Ch          Yes          1   \n",
       "4                         No      Ch          Yes          1   \n",
       "...                      ...     ...          ...        ...   \n",
       "9995                      No      No          Yes          0   \n",
       "9996                      No      No          Yes          0   \n",
       "9997                      No      No          Yes          0   \n",
       "9998                      No      No          Yes          0   \n",
       "9999                      No      No           No          0   \n",
       "\n",
       "                                            diag_1_desc  \\\n",
       "0     Acute pericarditis in diseases classified else...   \n",
       "1                      Malignant essential hypertension   \n",
       "2           Urinary tract infection, site not specified   \n",
       "3                  Respiratory abnormality, unspecified   \n",
       "4     Coronary atherosclerosis of unspecified type o...   \n",
       "...                                                 ...   \n",
       "9995  Coronary atherosclerosis of unspecified type o...   \n",
       "9996                           Atherosclerosis of aorta   \n",
       "9997                     Malignant neoplasm of prostate   \n",
       "9998                     Cellulitis and abscess of face   \n",
       "9999  Occlusion and stenosis of basilar artery witho...   \n",
       "\n",
       "                                            diag_2_desc  \\\n",
       "0                Secondary malignant neoplasm of kidney   \n",
       "1                   Spinal stenosis, unspecified region   \n",
       "2     Streptococcus infection in conditions classifi...   \n",
       "3     Hypertensive chronic kidney disease, malignant...   \n",
       "4     Chronic airway obstruction, not elsewhere clas...   \n",
       "...                                                 ...   \n",
       "9995  Diabetes mellitus without mention of complicat...   \n",
       "9996                            Endomyocardial fibrosis   \n",
       "9997  Hypertrophy (benign) of prostate without urina...   \n",
       "9998  Diabetes mellitus without mention of complicat...   \n",
       "9999                   Malignant essential hypertension   \n",
       "\n",
       "                                            diag_3_desc  \n",
       "0                 Congestive heart failure, unspecified  \n",
       "1     Diabetes mellitus without mention of complicat...  \n",
       "2                 Congestive heart failure, unspecified  \n",
       "3     Diabetes mellitus without mention of complicat...  \n",
       "4                      Malignant essential hypertension  \n",
       "...                                                 ...  \n",
       "9995                          Pure hypercholesterolemia  \n",
       "9996  Diabetes mellitus without mention of complicat...  \n",
       "9997                               Obesity, unspecified  \n",
       "9998                                                NaN  \n",
       "9999  Diabetes mellitus without mention of complicat...  \n",
       "\n",
       "[10000 rows x 51 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape, X.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\berka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\berka\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(10000, 3552)\n",
      "(10000, 1077) (10000, 1077) (10000, 1398)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,1077) (10000,1398) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-419ca3e8343d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiag1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mtext_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiag1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdiag2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdiag3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mtext_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,1077) (10000,1398) "
     ]
    }
   ],
   "source": [
    "#### we tried 2 approaches: \n",
    "#### 1) only use data from first diagnoses description\n",
    "#### 2) use all 3 and take the mean.\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    text = [w for w in word_tokens if not w in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return WordNetLemmatizer().lemmatize(text)\n",
    "\n",
    "\n",
    "\n",
    "OPTION1= False\n",
    "\n",
    "if OPTION1:\n",
    "    ### only take features from diag_desc_1\n",
    "    diag1 = data['diag_1_desc']\n",
    "\n",
    "    diag1 = diag1.replace(np.NaN, '').values\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_df=0.5, preprocessor=preprocess)\n",
    "    text_features = vectorizer.fit_transform(diag1)\n",
    "    text_features = pd.DataFrame.sparse.from_spmatrix(text_features)\n",
    "    text_features\n",
    "else:\n",
    "    textdata = pd.concat([data['diag_1_desc'], data['diag_2_desc'], data['diag_3_desc']], axis=0)\n",
    "    textdata.reset_index(inplace=True, drop=True)\n",
    "    textdata\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    textdata = textdata.replace(np.NaN, '').values\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_df=0.5, preprocessor=preprocess)\n",
    "    text_features = vectorizer.fit_transform(textdata)\n",
    "    text_features = pd.DataFrame.sparse.from_spmatrix(text_features).values\n",
    "\n",
    "    print(text_features)\n",
    "\n",
    "    text_features = text_features.reshape(10000,-1)\n",
    "    print(text_features.shape)\n",
    "    # text_features = text_features.toarray()\n",
    "    dim = int(text_features.shape[1]/3)\n",
    "    print(dim)\n",
    "    diag1 = text_features[:,:dim]\n",
    "    diag2 = text_features[:,dim:dim*2]\n",
    "    diag3 = text_features[:, 2*dim:]\n",
    "    \n",
    "    print(diag1.shape, diag2.shape, diag3.shape)\n",
    "\n",
    "    text_features = diag1 + diag2 + diag3 \n",
    "    text_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "text_features = pca.fit_transform(text_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "text_features = scaler.fit_transform(text_features)\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 45)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now add textual features to the categorical features\n",
    "X = np.concatenate((X, text_features), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 55)  and X_test shape: (2000, 55)\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   45.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.62025\n",
      "best parameters:  {'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 200, 'min_child_weight': 9, 'n_estimators': 500, 'objective': 'binary:logistic', 'seed': 11, 'subsample': 0.75}\n",
      "0 predictions: 894  1 predictions: 1106\n",
      "Accuracy: 0.6245 AUCROC: 0.6415356615622823 F1: 0.6045286993154292\n"
     ]
    }
   ],
   "source": [
    "# now do xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import auxilary\n",
    "\n",
    "X_train = X[:8000]\n",
    "y_train = y[:8000]\n",
    "y_test, X_test = y[8000:], X[8000:]\n",
    "\n",
    "print('X_train shape: {}  and X_test shape: {}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "scoring ={'auroc':    make_scorer(roc_auc_score, greater_is_better=True),\n",
    "        'f1_score': make_scorer(f1_score, average='micro', greater_is_better=True)}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=2.5, disable_defeult_eval_metric=0)\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "parameters_adaboost = {'n_estimators': [50, 100, 500, 1000]}\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'max_depth': [200],\n",
    "    'min_child_weight': [9],\n",
    "    'n_estimators': [500],\n",
    "    'seed': [11],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_delta_step': [0],\n",
    "    'subsample': [0.75]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=parameters, n_jobs=4, cv=4, scoring=scoring, verbose=3,\n",
    "                   refit='f1_score')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('best score: ', clf.best_score_)\n",
    "print('best parameters: ', clf.best_params_)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "print(\"0 predictions: {}  1 predictions: {}\".format(np.count_nonzero(y_predict == 0) ,np.count_nonzero(y_predict == 1)))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "aucroc_score = roc_auc_score(y_test, y_predict)\n",
    "f1Score = f1_score(y_test, y_predict)\n",
    "print('Accuracy: {} AUCROC: {} F1: {}'.format(accuracy, aucroc_score, f1Score))\n",
    "\n",
    "# best parameters:  {'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 500, 'objective': 'binary:logistic', 'seed': 11, 'subsample': 0.75}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
